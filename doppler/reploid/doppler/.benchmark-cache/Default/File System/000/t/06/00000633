{
  "version": "1.0",
  "modelId": "dcc83ea841ab6100d6b47a070329e1ba4cf78752",
  "modelType": "transformer",
  "architecture": "Gemma3ForCausalLM",
  "quantization": "Q4_K_M",
  "hashAlgorithm": "sha256",
  "config": {
    "architectures": [
      "Gemma3ForCausalLM"
    ],
    "attention_bias": false,
    "attention_dropout": 0,
    "attn_logit_softcapping": null,
    "bos_token_id": 2,
    "cache_implementation": "hybrid",
    "eos_token_id": [
      1,
      106
    ],
    "final_logit_softcapping": null,
    "head_dim": 256,
    "hidden_activation": "gelu_pytorch_tanh",
    "hidden_size": 1152,
    "initializer_range": 0.02,
    "intermediate_size": 6912,
    "max_position_embeddings": 32768,
    "model_type": "gemma3_text",
    "num_attention_heads": 4,
    "num_hidden_layers": 26,
    "num_key_value_heads": 1,
    "pad_token_id": 0,
    "query_pre_attn_scalar": 256,
    "rms_norm_eps": 0.000001,
    "rope_local_base_freq": 10000,
    "rope_scaling": null,
    "rope_theta": 1000000,
    "sliding_window": 512,
    "sliding_window_pattern": 6,
    "torch_dtype": "bfloat16",
    "transformers_version": "4.50.0.dev0",
    "use_cache": true,
    "vocab_size": 262144
  },
  "tokenizer": {
    "type": "huggingface",
    "file": "tokenizer.json",
    "vocabSize": 262144,
    "tokenizerType": "bpe"
  },
  "shards": [
    {
      "index": 0,
      "fileName": "shard_00000.bin",
      "size": 67108864,
      "hash": "ce0aa445c0342d8d331dcf0ea12420ec4d958f2aa0f9d03b0d11549afd51c51f",
      "hashAlgorithm": "sha256"
    },
    {
      "index": 1,
      "fileName": "shard_00001.bin",
      "size": 67108864,
      "hash": "139db6c33ea369fa5089fbbdbece91639d7be9abdb4330d4b6f6bbb69bd8eba8",
      "hashAlgorithm": "sha256"
    },
    {
      "index": 2,
      "fileName": "shard_00002.bin",
      "size": 67108864,
      "hash": "23bc7a67086efe16a19f78880349ed9a5c317765455e70a1e58a00876ab2e0e0",
      "hashAlgorithm": "sha256"
    },
    {
      "index": 3,
      "fileName": "shard_00003.bin",
      "size": 67108864,
      "hash": "a88c622d0c6e726c6c0c3e37397295073027ff0c330c1cc5d44da39c71c8cbf4",
      "hashAlgorithm": "sha256"
    },
    {
      "index": 4,
      "fileName": "shard_00004.bin",
      "size": 67108864,
      "hash": "98c6a4d591d7f5877a8d973e7680ff4969edeb8e5f9cbebbf944ddd7476b1ac4",
      "hashAlgorithm": "sha256"
    },
    {
      "index": 5,
      "fileName": "shard_00005.bin",
      "size": 67108864,
      "hash": "faf353ffab307ec5129f24adaa86869002557318356141c3bc9d71506f29ec98",
      "hashAlgorithm": "sha256"
    },
    {
      "index": 6,
      "fileName": "shard_00006.bin",
      "size": 67108864,
      "hash": "e97594ce663739291e96563d5ae421382ade6a4a2f242acbbb0199c9e79b3a19",
      "hashAlgorithm": "sha256"
    },
    {
      "index": 7,
      "fileName": "shard_00007.bin",
      "size": 67108864,
      "hash": "3b41e5abe58bdcb2016a89da6a38f25e2cb64f13fb626e4c10513b39c215a589",
      "hashAlgorithm": "sha256"
    },
    {
      "index": 8,
      "fileName": "shard_00008.bin",
      "size": 67108864,
      "hash": "68e2a3bc7312c7a7044a7676c41281059dcfa30df985fbf78acaaa2ce1c08e41",
      "hashAlgorithm": "sha256"
    },
    {
      "index": 9,
      "fileName": "shard_00009.bin",
      "size": 64989184,
      "hash": "06e71a558b15e6036b42040a8940269a7d1ac333d24dfa8dee5e62dc2237cbe8",
      "hashAlgorithm": "sha256"
    },
    {
      "index": 10,
      "fileName": "shard_00010.bin",
      "size": 60504064,
      "hash": "440fba3e14be8879f97d9c3212403327033eb92a1d90d8e7befcd1017819310b",
      "hashAlgorithm": "sha256"
    },
    {
      "index": 11,
      "fileName": "shard_00011.bin",
      "size": 60504064,
      "hash": "eacd2fdc1199087368713516f5e508a547b22188f7d895959190be791f408a2a",
      "hashAlgorithm": "sha256"
    },
    {
      "index": 12,
      "fileName": "shard_00012.bin",
      "size": 60504064,
      "hash": "3d913fbef5025c977adcd4c762cd45319e5ac22175da82e30aed6df8eb77551e",
      "hashAlgorithm": "sha256"
    },
    {
      "index": 13,
      "fileName": "shard_00013.bin",
      "size": 60504064,
      "hash": "972b4d936485b275a6067cd1e8a338315550d8e1943090b63ed79cc23e40a4f1",
      "hashAlgorithm": "sha256"
    },
    {
      "index": 14,
      "fileName": "shard_00014.bin",
      "size": 60504064,
      "hash": "d09003383bbd78f0d407ccd72a1531dc6feeea3eb9dab7fadfd125d825befc48",
      "hashAlgorithm": "sha256"
    },
    {
      "index": 15,
      "fileName": "shard_00015.bin",
      "size": 25770240,
      "hash": "68c92552170ce6c12f7e8b6a8d44683d6e527955d533fff685bce22cde11d13b",
      "hashAlgorithm": "sha256"
    }
  ],
  "tensors": {
    "model.embed_tokens.weight": {
      "shardIndex": 0,
      "offset": 0,
      "size": 603979776,
      "shape": [
        262144,
        1152
      ],
      "dtype": "BF16",
      "spans": [
        {
          "shardIndex": 0,
          "offset": 0,
          "size": 67108864
        },
        {
          "shardIndex": 1,
          "offset": 0,
          "size": 67108864
        },
        {
          "shardIndex": 2,
          "offset": 0,
          "size": 67108864
        },
        {
          "shardIndex": 3,
          "offset": 0,
          "size": 67108864
        },
        {
          "shardIndex": 4,
          "offset": 0,
          "size": 67108864
        },
        {
          "shardIndex": 5,
          "offset": 0,
          "size": 67108864
        },
        {
          "shardIndex": 6,
          "offset": 0,
          "size": 67108864
        },
        {
          "shardIndex": 7,
          "offset": 0,
          "size": 67108864
        },
        {
          "shardIndex": 8,
          "offset": 0,
          "size": 67108864
        }
      ]
    },
    "model.layers.0.input_layernorm.weight": {
      "shardIndex": 9,
      "offset": 0,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.0.mlp.down_proj.weight": {
      "shardIndex": 9,
      "offset": 4096,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.0.mlp.gate_up_proj.weight": {
      "shardIndex": 9,
      "offset": 4485120,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.0.post_attention_layernorm.weight": {
      "shardIndex": 9,
      "offset": 13443072,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.0.post_feedforward_layernorm.weight": {
      "shardIndex": 9,
      "offset": 13447168,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.0.pre_feedforward_layernorm.weight": {
      "shardIndex": 9,
      "offset": 13451264,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.0.self_attn.k_norm.weight": {
      "shardIndex": 9,
      "offset": 13455360,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.0.self_attn.k_proj.weight": {
      "shardIndex": 9,
      "offset": 13459456,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.0.self_attn.o_proj.weight": {
      "shardIndex": 9,
      "offset": 13627392,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.0.self_attn.q_norm.weight": {
      "shardIndex": 9,
      "offset": 14290944,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.0.self_attn.q_proj.weight": {
      "shardIndex": 9,
      "offset": 14295040,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.0.self_attn.v_proj.weight": {
      "shardIndex": 9,
      "offset": 14958592,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.1.input_layernorm.weight": {
      "shardIndex": 9,
      "offset": 15126528,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.1.mlp.down_proj.weight": {
      "shardIndex": 9,
      "offset": 15130624,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.1.mlp.gate_up_proj.weight": {
      "shardIndex": 9,
      "offset": 19611648,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.1.post_attention_layernorm.weight": {
      "shardIndex": 9,
      "offset": 28569600,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.1.post_feedforward_layernorm.weight": {
      "shardIndex": 9,
      "offset": 28573696,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.1.pre_feedforward_layernorm.weight": {
      "shardIndex": 9,
      "offset": 28577792,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.1.self_attn.k_norm.weight": {
      "shardIndex": 9,
      "offset": 28581888,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.1.self_attn.k_proj.weight": {
      "shardIndex": 9,
      "offset": 28585984,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.1.self_attn.o_proj.weight": {
      "shardIndex": 9,
      "offset": 28753920,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.1.self_attn.q_norm.weight": {
      "shardIndex": 9,
      "offset": 29417472,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.1.self_attn.q_proj.weight": {
      "shardIndex": 9,
      "offset": 29421568,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.1.self_attn.v_proj.weight": {
      "shardIndex": 9,
      "offset": 30085120,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.10.input_layernorm.weight": {
      "shardIndex": 9,
      "offset": 30253056,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.10.mlp.down_proj.weight": {
      "shardIndex": 9,
      "offset": 30257152,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.10.mlp.gate_up_proj.weight": {
      "shardIndex": 9,
      "offset": 34738176,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.10.post_attention_layernorm.weight": {
      "shardIndex": 9,
      "offset": 43696128,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.10.post_feedforward_layernorm.weight": {
      "shardIndex": 9,
      "offset": 43700224,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.10.pre_feedforward_layernorm.weight": {
      "shardIndex": 9,
      "offset": 43704320,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.10.self_attn.k_norm.weight": {
      "shardIndex": 9,
      "offset": 43708416,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.10.self_attn.k_proj.weight": {
      "shardIndex": 9,
      "offset": 43712512,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.10.self_attn.o_proj.weight": {
      "shardIndex": 9,
      "offset": 43880448,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.10.self_attn.q_norm.weight": {
      "shardIndex": 9,
      "offset": 44544000,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.10.self_attn.q_proj.weight": {
      "shardIndex": 9,
      "offset": 44548096,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.10.self_attn.v_proj.weight": {
      "shardIndex": 9,
      "offset": 45211648,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.11.input_layernorm.weight": {
      "shardIndex": 9,
      "offset": 45379584,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.11.mlp.down_proj.weight": {
      "shardIndex": 9,
      "offset": 45383680,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.11.mlp.gate_up_proj.weight": {
      "shardIndex": 9,
      "offset": 49864704,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.11.post_attention_layernorm.weight": {
      "shardIndex": 9,
      "offset": 58822656,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.11.post_feedforward_layernorm.weight": {
      "shardIndex": 9,
      "offset": 58826752,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.11.pre_feedforward_layernorm.weight": {
      "shardIndex": 9,
      "offset": 58830848,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.11.self_attn.k_norm.weight": {
      "shardIndex": 9,
      "offset": 58834944,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.11.self_attn.k_proj.weight": {
      "shardIndex": 9,
      "offset": 58839040,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.11.self_attn.o_proj.weight": {
      "shardIndex": 9,
      "offset": 59006976,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.11.self_attn.q_norm.weight": {
      "shardIndex": 9,
      "offset": 59670528,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.11.self_attn.q_proj.weight": {
      "shardIndex": 9,
      "offset": 59674624,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.11.self_attn.v_proj.weight": {
      "shardIndex": 9,
      "offset": 60338176,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.12.input_layernorm.weight": {
      "shardIndex": 9,
      "offset": 60506112,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.12.mlp.down_proj.weight": {
      "shardIndex": 9,
      "offset": 60510208,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.12.mlp.gate_up_proj.weight": {
      "shardIndex": 10,
      "offset": 0,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.12.post_attention_layernorm.weight": {
      "shardIndex": 10,
      "offset": 8957952,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.12.post_feedforward_layernorm.weight": {
      "shardIndex": 10,
      "offset": 8962048,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.12.pre_feedforward_layernorm.weight": {
      "shardIndex": 10,
      "offset": 8966144,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.12.self_attn.k_norm.weight": {
      "shardIndex": 10,
      "offset": 8970240,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.12.self_attn.k_proj.weight": {
      "shardIndex": 10,
      "offset": 8974336,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.12.self_attn.o_proj.weight": {
      "shardIndex": 10,
      "offset": 9142272,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.12.self_attn.q_norm.weight": {
      "shardIndex": 10,
      "offset": 9805824,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.12.self_attn.q_proj.weight": {
      "shardIndex": 10,
      "offset": 9809920,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.12.self_attn.v_proj.weight": {
      "shardIndex": 10,
      "offset": 10473472,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.13.input_layernorm.weight": {
      "shardIndex": 10,
      "offset": 10641408,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.13.mlp.down_proj.weight": {
      "shardIndex": 10,
      "offset": 10645504,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.13.mlp.gate_up_proj.weight": {
      "shardIndex": 10,
      "offset": 15126528,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.13.post_attention_layernorm.weight": {
      "shardIndex": 10,
      "offset": 24084480,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.13.post_feedforward_layernorm.weight": {
      "shardIndex": 10,
      "offset": 24088576,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.13.pre_feedforward_layernorm.weight": {
      "shardIndex": 10,
      "offset": 24092672,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.13.self_attn.k_norm.weight": {
      "shardIndex": 10,
      "offset": 24096768,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.13.self_attn.k_proj.weight": {
      "shardIndex": 10,
      "offset": 24100864,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.13.self_attn.o_proj.weight": {
      "shardIndex": 10,
      "offset": 24268800,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.13.self_attn.q_norm.weight": {
      "shardIndex": 10,
      "offset": 24932352,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.13.self_attn.q_proj.weight": {
      "shardIndex": 10,
      "offset": 24936448,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.13.self_attn.v_proj.weight": {
      "shardIndex": 10,
      "offset": 25600000,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.14.input_layernorm.weight": {
      "shardIndex": 10,
      "offset": 25767936,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.14.mlp.down_proj.weight": {
      "shardIndex": 10,
      "offset": 25772032,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.14.mlp.gate_up_proj.weight": {
      "shardIndex": 10,
      "offset": 30253056,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.14.post_attention_layernorm.weight": {
      "shardIndex": 10,
      "offset": 39211008,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.14.post_feedforward_layernorm.weight": {
      "shardIndex": 10,
      "offset": 39215104,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.14.pre_feedforward_layernorm.weight": {
      "shardIndex": 10,
      "offset": 39219200,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.14.self_attn.k_norm.weight": {
      "shardIndex": 10,
      "offset": 39223296,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.14.self_attn.k_proj.weight": {
      "shardIndex": 10,
      "offset": 39227392,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.14.self_attn.o_proj.weight": {
      "shardIndex": 10,
      "offset": 39395328,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.14.self_attn.q_norm.weight": {
      "shardIndex": 10,
      "offset": 40058880,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.14.self_attn.q_proj.weight": {
      "shardIndex": 10,
      "offset": 40062976,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.14.self_attn.v_proj.weight": {
      "shardIndex": 10,
      "offset": 40726528,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.15.input_layernorm.weight": {
      "shardIndex": 10,
      "offset": 40894464,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.15.mlp.down_proj.weight": {
      "shardIndex": 10,
      "offset": 40898560,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.15.mlp.gate_up_proj.weight": {
      "shardIndex": 10,
      "offset": 45379584,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.15.post_attention_layernorm.weight": {
      "shardIndex": 10,
      "offset": 54337536,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.15.post_feedforward_layernorm.weight": {
      "shardIndex": 10,
      "offset": 54341632,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.15.pre_feedforward_layernorm.weight": {
      "shardIndex": 10,
      "offset": 54345728,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.15.self_attn.k_norm.weight": {
      "shardIndex": 10,
      "offset": 54349824,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.15.self_attn.k_proj.weight": {
      "shardIndex": 10,
      "offset": 54353920,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.15.self_attn.o_proj.weight": {
      "shardIndex": 10,
      "offset": 54521856,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.15.self_attn.q_norm.weight": {
      "shardIndex": 10,
      "offset": 55185408,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.15.self_attn.q_proj.weight": {
      "shardIndex": 10,
      "offset": 55189504,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.15.self_attn.v_proj.weight": {
      "shardIndex": 10,
      "offset": 55853056,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.16.input_layernorm.weight": {
      "shardIndex": 10,
      "offset": 56020992,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.16.mlp.down_proj.weight": {
      "shardIndex": 10,
      "offset": 56025088,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.16.mlp.gate_up_proj.weight": {
      "shardIndex": 11,
      "offset": 0,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.16.post_attention_layernorm.weight": {
      "shardIndex": 11,
      "offset": 8957952,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.16.post_feedforward_layernorm.weight": {
      "shardIndex": 11,
      "offset": 8962048,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.16.pre_feedforward_layernorm.weight": {
      "shardIndex": 11,
      "offset": 8966144,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.16.self_attn.k_norm.weight": {
      "shardIndex": 11,
      "offset": 8970240,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.16.self_attn.k_proj.weight": {
      "shardIndex": 11,
      "offset": 8974336,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.16.self_attn.o_proj.weight": {
      "shardIndex": 11,
      "offset": 9142272,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.16.self_attn.q_norm.weight": {
      "shardIndex": 11,
      "offset": 9805824,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.16.self_attn.q_proj.weight": {
      "shardIndex": 11,
      "offset": 9809920,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.16.self_attn.v_proj.weight": {
      "shardIndex": 11,
      "offset": 10473472,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.17.input_layernorm.weight": {
      "shardIndex": 11,
      "offset": 10641408,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.17.mlp.down_proj.weight": {
      "shardIndex": 11,
      "offset": 10645504,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.17.mlp.gate_up_proj.weight": {
      "shardIndex": 11,
      "offset": 15126528,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.17.post_attention_layernorm.weight": {
      "shardIndex": 11,
      "offset": 24084480,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.17.post_feedforward_layernorm.weight": {
      "shardIndex": 11,
      "offset": 24088576,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.17.pre_feedforward_layernorm.weight": {
      "shardIndex": 11,
      "offset": 24092672,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.17.self_attn.k_norm.weight": {
      "shardIndex": 11,
      "offset": 24096768,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.17.self_attn.k_proj.weight": {
      "shardIndex": 11,
      "offset": 24100864,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.17.self_attn.o_proj.weight": {
      "shardIndex": 11,
      "offset": 24268800,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.17.self_attn.q_norm.weight": {
      "shardIndex": 11,
      "offset": 24932352,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.17.self_attn.q_proj.weight": {
      "shardIndex": 11,
      "offset": 24936448,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.17.self_attn.v_proj.weight": {
      "shardIndex": 11,
      "offset": 25600000,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.18.input_layernorm.weight": {
      "shardIndex": 11,
      "offset": 25767936,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.18.mlp.down_proj.weight": {
      "shardIndex": 11,
      "offset": 25772032,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.18.mlp.gate_up_proj.weight": {
      "shardIndex": 11,
      "offset": 30253056,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.18.post_attention_layernorm.weight": {
      "shardIndex": 11,
      "offset": 39211008,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.18.post_feedforward_layernorm.weight": {
      "shardIndex": 11,
      "offset": 39215104,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.18.pre_feedforward_layernorm.weight": {
      "shardIndex": 11,
      "offset": 39219200,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.18.self_attn.k_norm.weight": {
      "shardIndex": 11,
      "offset": 39223296,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.18.self_attn.k_proj.weight": {
      "shardIndex": 11,
      "offset": 39227392,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.18.self_attn.o_proj.weight": {
      "shardIndex": 11,
      "offset": 39395328,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.18.self_attn.q_norm.weight": {
      "shardIndex": 11,
      "offset": 40058880,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.18.self_attn.q_proj.weight": {
      "shardIndex": 11,
      "offset": 40062976,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.18.self_attn.v_proj.weight": {
      "shardIndex": 11,
      "offset": 40726528,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.19.input_layernorm.weight": {
      "shardIndex": 11,
      "offset": 40894464,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.19.mlp.down_proj.weight": {
      "shardIndex": 11,
      "offset": 40898560,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.19.mlp.gate_up_proj.weight": {
      "shardIndex": 11,
      "offset": 45379584,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.19.post_attention_layernorm.weight": {
      "shardIndex": 11,
      "offset": 54337536,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.19.post_feedforward_layernorm.weight": {
      "shardIndex": 11,
      "offset": 54341632,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.19.pre_feedforward_layernorm.weight": {
      "shardIndex": 11,
      "offset": 54345728,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.19.self_attn.k_norm.weight": {
      "shardIndex": 11,
      "offset": 54349824,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.19.self_attn.k_proj.weight": {
      "shardIndex": 11,
      "offset": 54353920,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.19.self_attn.o_proj.weight": {
      "shardIndex": 11,
      "offset": 54521856,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.19.self_attn.q_norm.weight": {
      "shardIndex": 11,
      "offset": 55185408,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.19.self_attn.q_proj.weight": {
      "shardIndex": 11,
      "offset": 55189504,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.19.self_attn.v_proj.weight": {
      "shardIndex": 11,
      "offset": 55853056,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.2.input_layernorm.weight": {
      "shardIndex": 11,
      "offset": 56020992,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.2.mlp.down_proj.weight": {
      "shardIndex": 11,
      "offset": 56025088,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.2.mlp.gate_up_proj.weight": {
      "shardIndex": 12,
      "offset": 0,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.2.post_attention_layernorm.weight": {
      "shardIndex": 12,
      "offset": 8957952,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.2.post_feedforward_layernorm.weight": {
      "shardIndex": 12,
      "offset": 8962048,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.2.pre_feedforward_layernorm.weight": {
      "shardIndex": 12,
      "offset": 8966144,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.2.self_attn.k_norm.weight": {
      "shardIndex": 12,
      "offset": 8970240,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.2.self_attn.k_proj.weight": {
      "shardIndex": 12,
      "offset": 8974336,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.2.self_attn.o_proj.weight": {
      "shardIndex": 12,
      "offset": 9142272,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.2.self_attn.q_norm.weight": {
      "shardIndex": 12,
      "offset": 9805824,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.2.self_attn.q_proj.weight": {
      "shardIndex": 12,
      "offset": 9809920,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.2.self_attn.v_proj.weight": {
      "shardIndex": 12,
      "offset": 10473472,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.20.input_layernorm.weight": {
      "shardIndex": 12,
      "offset": 10641408,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.20.mlp.down_proj.weight": {
      "shardIndex": 12,
      "offset": 10645504,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.20.mlp.gate_up_proj.weight": {
      "shardIndex": 12,
      "offset": 15126528,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.20.post_attention_layernorm.weight": {
      "shardIndex": 12,
      "offset": 24084480,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.20.post_feedforward_layernorm.weight": {
      "shardIndex": 12,
      "offset": 24088576,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.20.pre_feedforward_layernorm.weight": {
      "shardIndex": 12,
      "offset": 24092672,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.20.self_attn.k_norm.weight": {
      "shardIndex": 12,
      "offset": 24096768,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.20.self_attn.k_proj.weight": {
      "shardIndex": 12,
      "offset": 24100864,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.20.self_attn.o_proj.weight": {
      "shardIndex": 12,
      "offset": 24268800,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.20.self_attn.q_norm.weight": {
      "shardIndex": 12,
      "offset": 24932352,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.20.self_attn.q_proj.weight": {
      "shardIndex": 12,
      "offset": 24936448,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.20.self_attn.v_proj.weight": {
      "shardIndex": 12,
      "offset": 25600000,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.21.input_layernorm.weight": {
      "shardIndex": 12,
      "offset": 25767936,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.21.mlp.down_proj.weight": {
      "shardIndex": 12,
      "offset": 25772032,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.21.mlp.gate_up_proj.weight": {
      "shardIndex": 12,
      "offset": 30253056,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.21.post_attention_layernorm.weight": {
      "shardIndex": 12,
      "offset": 39211008,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.21.post_feedforward_layernorm.weight": {
      "shardIndex": 12,
      "offset": 39215104,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.21.pre_feedforward_layernorm.weight": {
      "shardIndex": 12,
      "offset": 39219200,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.21.self_attn.k_norm.weight": {
      "shardIndex": 12,
      "offset": 39223296,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.21.self_attn.k_proj.weight": {
      "shardIndex": 12,
      "offset": 39227392,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.21.self_attn.o_proj.weight": {
      "shardIndex": 12,
      "offset": 39395328,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.21.self_attn.q_norm.weight": {
      "shardIndex": 12,
      "offset": 40058880,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.21.self_attn.q_proj.weight": {
      "shardIndex": 12,
      "offset": 40062976,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.21.self_attn.v_proj.weight": {
      "shardIndex": 12,
      "offset": 40726528,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.22.input_layernorm.weight": {
      "shardIndex": 12,
      "offset": 40894464,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.22.mlp.down_proj.weight": {
      "shardIndex": 12,
      "offset": 40898560,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.22.mlp.gate_up_proj.weight": {
      "shardIndex": 12,
      "offset": 45379584,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.22.post_attention_layernorm.weight": {
      "shardIndex": 12,
      "offset": 54337536,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.22.post_feedforward_layernorm.weight": {
      "shardIndex": 12,
      "offset": 54341632,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.22.pre_feedforward_layernorm.weight": {
      "shardIndex": 12,
      "offset": 54345728,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.22.self_attn.k_norm.weight": {
      "shardIndex": 12,
      "offset": 54349824,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.22.self_attn.k_proj.weight": {
      "shardIndex": 12,
      "offset": 54353920,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.22.self_attn.o_proj.weight": {
      "shardIndex": 12,
      "offset": 54521856,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.22.self_attn.q_norm.weight": {
      "shardIndex": 12,
      "offset": 55185408,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.22.self_attn.q_proj.weight": {
      "shardIndex": 12,
      "offset": 55189504,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.22.self_attn.v_proj.weight": {
      "shardIndex": 12,
      "offset": 55853056,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.23.input_layernorm.weight": {
      "shardIndex": 12,
      "offset": 56020992,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.23.mlp.down_proj.weight": {
      "shardIndex": 12,
      "offset": 56025088,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.23.mlp.gate_up_proj.weight": {
      "shardIndex": 13,
      "offset": 0,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.23.post_attention_layernorm.weight": {
      "shardIndex": 13,
      "offset": 8957952,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.23.post_feedforward_layernorm.weight": {
      "shardIndex": 13,
      "offset": 8962048,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.23.pre_feedforward_layernorm.weight": {
      "shardIndex": 13,
      "offset": 8966144,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.23.self_attn.k_norm.weight": {
      "shardIndex": 13,
      "offset": 8970240,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.23.self_attn.k_proj.weight": {
      "shardIndex": 13,
      "offset": 8974336,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.23.self_attn.o_proj.weight": {
      "shardIndex": 13,
      "offset": 9142272,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.23.self_attn.q_norm.weight": {
      "shardIndex": 13,
      "offset": 9805824,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.23.self_attn.q_proj.weight": {
      "shardIndex": 13,
      "offset": 9809920,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.23.self_attn.v_proj.weight": {
      "shardIndex": 13,
      "offset": 10473472,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.24.input_layernorm.weight": {
      "shardIndex": 13,
      "offset": 10641408,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.24.mlp.down_proj.weight": {
      "shardIndex": 13,
      "offset": 10645504,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.24.mlp.gate_up_proj.weight": {
      "shardIndex": 13,
      "offset": 15126528,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.24.post_attention_layernorm.weight": {
      "shardIndex": 13,
      "offset": 24084480,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.24.post_feedforward_layernorm.weight": {
      "shardIndex": 13,
      "offset": 24088576,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.24.pre_feedforward_layernorm.weight": {
      "shardIndex": 13,
      "offset": 24092672,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.24.self_attn.k_norm.weight": {
      "shardIndex": 13,
      "offset": 24096768,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.24.self_attn.k_proj.weight": {
      "shardIndex": 13,
      "offset": 24100864,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.24.self_attn.o_proj.weight": {
      "shardIndex": 13,
      "offset": 24268800,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.24.self_attn.q_norm.weight": {
      "shardIndex": 13,
      "offset": 24932352,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.24.self_attn.q_proj.weight": {
      "shardIndex": 13,
      "offset": 24936448,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.24.self_attn.v_proj.weight": {
      "shardIndex": 13,
      "offset": 25600000,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.25.input_layernorm.weight": {
      "shardIndex": 13,
      "offset": 25767936,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.25.mlp.down_proj.weight": {
      "shardIndex": 13,
      "offset": 25772032,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.25.mlp.gate_up_proj.weight": {
      "shardIndex": 13,
      "offset": 30253056,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.25.post_attention_layernorm.weight": {
      "shardIndex": 13,
      "offset": 39211008,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.25.post_feedforward_layernorm.weight": {
      "shardIndex": 13,
      "offset": 39215104,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.25.pre_feedforward_layernorm.weight": {
      "shardIndex": 13,
      "offset": 39219200,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.25.self_attn.k_norm.weight": {
      "shardIndex": 13,
      "offset": 39223296,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.25.self_attn.k_proj.weight": {
      "shardIndex": 13,
      "offset": 39227392,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.25.self_attn.o_proj.weight": {
      "shardIndex": 13,
      "offset": 39395328,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.25.self_attn.q_norm.weight": {
      "shardIndex": 13,
      "offset": 40058880,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.25.self_attn.q_proj.weight": {
      "shardIndex": 13,
      "offset": 40062976,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.25.self_attn.v_proj.weight": {
      "shardIndex": 13,
      "offset": 40726528,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.3.input_layernorm.weight": {
      "shardIndex": 13,
      "offset": 40894464,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.3.mlp.down_proj.weight": {
      "shardIndex": 13,
      "offset": 40898560,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.3.mlp.gate_up_proj.weight": {
      "shardIndex": 13,
      "offset": 45379584,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.3.post_attention_layernorm.weight": {
      "shardIndex": 13,
      "offset": 54337536,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.3.post_feedforward_layernorm.weight": {
      "shardIndex": 13,
      "offset": 54341632,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.3.pre_feedforward_layernorm.weight": {
      "shardIndex": 13,
      "offset": 54345728,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.3.self_attn.k_norm.weight": {
      "shardIndex": 13,
      "offset": 54349824,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.3.self_attn.k_proj.weight": {
      "shardIndex": 13,
      "offset": 54353920,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.3.self_attn.o_proj.weight": {
      "shardIndex": 13,
      "offset": 54521856,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.3.self_attn.q_norm.weight": {
      "shardIndex": 13,
      "offset": 55185408,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.3.self_attn.q_proj.weight": {
      "shardIndex": 13,
      "offset": 55189504,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.3.self_attn.v_proj.weight": {
      "shardIndex": 13,
      "offset": 55853056,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.4.input_layernorm.weight": {
      "shardIndex": 13,
      "offset": 56020992,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.4.mlp.down_proj.weight": {
      "shardIndex": 13,
      "offset": 56025088,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.4.mlp.gate_up_proj.weight": {
      "shardIndex": 14,
      "offset": 0,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.4.post_attention_layernorm.weight": {
      "shardIndex": 14,
      "offset": 8957952,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.4.post_feedforward_layernorm.weight": {
      "shardIndex": 14,
      "offset": 8962048,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.4.pre_feedforward_layernorm.weight": {
      "shardIndex": 14,
      "offset": 8966144,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.4.self_attn.k_norm.weight": {
      "shardIndex": 14,
      "offset": 8970240,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.4.self_attn.k_proj.weight": {
      "shardIndex": 14,
      "offset": 8974336,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.4.self_attn.o_proj.weight": {
      "shardIndex": 14,
      "offset": 9142272,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.4.self_attn.q_norm.weight": {
      "shardIndex": 14,
      "offset": 9805824,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.4.self_attn.q_proj.weight": {
      "shardIndex": 14,
      "offset": 9809920,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.4.self_attn.v_proj.weight": {
      "shardIndex": 14,
      "offset": 10473472,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.5.input_layernorm.weight": {
      "shardIndex": 14,
      "offset": 10641408,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.5.mlp.down_proj.weight": {
      "shardIndex": 14,
      "offset": 10645504,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.5.mlp.gate_up_proj.weight": {
      "shardIndex": 14,
      "offset": 15126528,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.5.post_attention_layernorm.weight": {
      "shardIndex": 14,
      "offset": 24084480,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.5.post_feedforward_layernorm.weight": {
      "shardIndex": 14,
      "offset": 24088576,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.5.pre_feedforward_layernorm.weight": {
      "shardIndex": 14,
      "offset": 24092672,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.5.self_attn.k_norm.weight": {
      "shardIndex": 14,
      "offset": 24096768,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.5.self_attn.k_proj.weight": {
      "shardIndex": 14,
      "offset": 24100864,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.5.self_attn.o_proj.weight": {
      "shardIndex": 14,
      "offset": 24268800,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.5.self_attn.q_norm.weight": {
      "shardIndex": 14,
      "offset": 24932352,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.5.self_attn.q_proj.weight": {
      "shardIndex": 14,
      "offset": 24936448,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.5.self_attn.v_proj.weight": {
      "shardIndex": 14,
      "offset": 25600000,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.6.input_layernorm.weight": {
      "shardIndex": 14,
      "offset": 25767936,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.6.mlp.down_proj.weight": {
      "shardIndex": 14,
      "offset": 25772032,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.6.mlp.gate_up_proj.weight": {
      "shardIndex": 14,
      "offset": 30253056,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.6.post_attention_layernorm.weight": {
      "shardIndex": 14,
      "offset": 39211008,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.6.post_feedforward_layernorm.weight": {
      "shardIndex": 14,
      "offset": 39215104,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.6.pre_feedforward_layernorm.weight": {
      "shardIndex": 14,
      "offset": 39219200,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.6.self_attn.k_norm.weight": {
      "shardIndex": 14,
      "offset": 39223296,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.6.self_attn.k_proj.weight": {
      "shardIndex": 14,
      "offset": 39227392,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.6.self_attn.o_proj.weight": {
      "shardIndex": 14,
      "offset": 39395328,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.6.self_attn.q_norm.weight": {
      "shardIndex": 14,
      "offset": 40058880,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.6.self_attn.q_proj.weight": {
      "shardIndex": 14,
      "offset": 40062976,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.6.self_attn.v_proj.weight": {
      "shardIndex": 14,
      "offset": 40726528,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.7.input_layernorm.weight": {
      "shardIndex": 14,
      "offset": 40894464,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.7.mlp.down_proj.weight": {
      "shardIndex": 14,
      "offset": 40898560,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.7.mlp.gate_up_proj.weight": {
      "shardIndex": 14,
      "offset": 45379584,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.7.post_attention_layernorm.weight": {
      "shardIndex": 14,
      "offset": 54337536,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.7.post_feedforward_layernorm.weight": {
      "shardIndex": 14,
      "offset": 54341632,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.7.pre_feedforward_layernorm.weight": {
      "shardIndex": 14,
      "offset": 54345728,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.7.self_attn.k_norm.weight": {
      "shardIndex": 14,
      "offset": 54349824,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.7.self_attn.k_proj.weight": {
      "shardIndex": 14,
      "offset": 54353920,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.7.self_attn.o_proj.weight": {
      "shardIndex": 14,
      "offset": 54521856,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.7.self_attn.q_norm.weight": {
      "shardIndex": 14,
      "offset": 55185408,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.7.self_attn.q_proj.weight": {
      "shardIndex": 14,
      "offset": 55189504,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.7.self_attn.v_proj.weight": {
      "shardIndex": 14,
      "offset": 55853056,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.8.input_layernorm.weight": {
      "shardIndex": 14,
      "offset": 56020992,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.8.mlp.down_proj.weight": {
      "shardIndex": 14,
      "offset": 56025088,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.8.mlp.gate_up_proj.weight": {
      "shardIndex": 15,
      "offset": 0,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.8.post_attention_layernorm.weight": {
      "shardIndex": 15,
      "offset": 8957952,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.8.post_feedforward_layernorm.weight": {
      "shardIndex": 15,
      "offset": 8962048,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.8.pre_feedforward_layernorm.weight": {
      "shardIndex": 15,
      "offset": 8966144,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.8.self_attn.k_norm.weight": {
      "shardIndex": 15,
      "offset": 8970240,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.8.self_attn.k_proj.weight": {
      "shardIndex": 15,
      "offset": 8974336,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.8.self_attn.o_proj.weight": {
      "shardIndex": 15,
      "offset": 9142272,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.8.self_attn.q_norm.weight": {
      "shardIndex": 15,
      "offset": 9805824,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.8.self_attn.q_proj.weight": {
      "shardIndex": 15,
      "offset": 9809920,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.8.self_attn.v_proj.weight": {
      "shardIndex": 15,
      "offset": 10473472,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.9.input_layernorm.weight": {
      "shardIndex": 15,
      "offset": 10641408,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.9.mlp.down_proj.weight": {
      "shardIndex": 15,
      "offset": 10645504,
      "size": 4478976,
      "shape": [
        1152,
        6912
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.9.mlp.gate_up_proj.weight": {
      "shardIndex": 15,
      "offset": 15126528,
      "size": 8957952,
      "shape": [
        13824,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.9.post_attention_layernorm.weight": {
      "shardIndex": 15,
      "offset": 24084480,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.9.post_feedforward_layernorm.weight": {
      "shardIndex": 15,
      "offset": 24088576,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.9.pre_feedforward_layernorm.weight": {
      "shardIndex": 15,
      "offset": 24092672,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    },
    "model.layers.9.self_attn.k_norm.weight": {
      "shardIndex": 15,
      "offset": 24096768,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.9.self_attn.k_proj.weight": {
      "shardIndex": 15,
      "offset": 24100864,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.9.self_attn.o_proj.weight": {
      "shardIndex": 15,
      "offset": 24268800,
      "size": 663552,
      "shape": [
        1152,
        1024
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.9.self_attn.q_norm.weight": {
      "shardIndex": 15,
      "offset": 24932352,
      "size": 512,
      "shape": [
        256
      ],
      "dtype": "BF16"
    },
    "model.layers.9.self_attn.q_proj.weight": {
      "shardIndex": 15,
      "offset": 24936448,
      "size": 663552,
      "shape": [
        1024,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.layers.9.self_attn.v_proj.weight": {
      "shardIndex": 15,
      "offset": 25600000,
      "size": 165888,
      "shape": [
        256,
        1152
      ],
      "dtype": "Q4_K_M"
    },
    "model.norm.weight": {
      "shardIndex": 15,
      "offset": 25767936,
      "size": 2304,
      "shape": [
        1152
      ],
      "dtype": "BF16"
    }
  },
  "moeConfig": null,
  "totalSize": 997259520,
  "tensorCount": 314
}